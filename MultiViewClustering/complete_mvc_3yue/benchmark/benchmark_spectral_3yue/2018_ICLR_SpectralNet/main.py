import torch
import numpy as np
import sklearn.metrics as metrics
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from munkres import Munkres
from model import AETrainer, SiameseTrainer, SpectralTrainer
from utils import load_data
from utils import build_ann, get_affinity_matrix, get_laplacian, plot_laplacian_eigenvectors

def calculate_cost_matrix(C: np.ndarray, n_clusters: int) -> np.ndarray:
    # Calculates the cost matrix for the Munkres algorithm.
    cost_matrix = np.zeros((n_clusters, n_clusters))
    # cost_matrix[i,j] will be the cost of assigning cluster i to label j
    for j in range(n_clusters):
        s = np.sum(C[:, j])  # number of examples in cluster i
        for i in range(n_clusters):
            t = C[i, j]
            cost_matrix[j, i] = s - t
    return cost_matrix

def get_cluster_labels_from_indices(indices: np.ndarray) -> np.ndarray:
    # Gets the cluster labels from their indices.
    num_clusters = len(indices)
    cluster_labels = np.zeros(num_clusters)
    for i in range(num_clusters):
        cluster_labels[i] = indices[i][1]
    return cluster_labels

class Metrics:
    @staticmethod
    def acc_score(cluster_assignments: np.ndarray, y: np.ndarray, n_clusters: int) -> float:
        confusion_matrix = metrics.confusion_matrix(y, cluster_assignments, labels=None)
        cost_matrix = calculate_cost_matrix(confusion_matrix, n_clusters=n_clusters)
        indices = Munkres().compute(cost_matrix)
        kmeans_to_true_cluster_labels = get_cluster_labels_from_indices(indices)
        y_pred = kmeans_to_true_cluster_labels[cluster_assignments]
        print(metrics.confusion_matrix(y, y_pred))
        accuracy = np.mean(y_pred == y)
        return accuracy

    @staticmethod
    def nmi_score(cluster_assignments: np.ndarray, y: np.ndarray) -> float:
        return metrics.normalized_mutual_info_score(cluster_assignments, y)

class SpectralNet:
    def __init__(
        self,
        n_clusters: int,
        should_use_ae: bool = False,
        should_use_siamese: bool = False,
        is_sparse_graph: bool = False,
        ae_hiddens: list = [512, 512, 2048, 10],
        ae_epochs: int = 40,
        ae_lr: float = 1e-3,
        ae_lr_decay: float = 0.1,
        ae_min_lr: float = 1e-7,
        ae_patience: int = 10,
        ae_batch_size: int = 256,
        siamese_hiddens: list = [1024, 1024, 512, 10],
        siamese_epochs: int = 30,
        siamese_lr: float = 1e-3,
        siamese_lr_decay: float = 0.1,
        siamese_min_lr: float = 1e-7,
        siamese_patience: int = 10,
        siamese_n_nbg: int = 2,
        siamese_use_approx: bool = False,
        siamese_batch_size: int = 128,
        spectral_hiddens: list = [1024, 1024, 512, 10],
        spectral_epochs: int = 30,
        spectral_lr: float = 1e-3,
        spectral_lr_decay: float = 0.1,
        spectral_min_lr: float = 1e-8,
        spectral_patience: int = 10,
        spectral_batch_size: int = 1024,
        spectral_n_nbg: int = 30,
        spectral_scale_k: int = 15,
        spectral_is_local_scale: bool = True,
    ):
        """SpectralNet is a class for implementing a Deep learning model that performs spectral clustering.
        This model optionally utilizes Autoencoders (AE) and Siamese networks for training.
        Parameters
        ----------
        n_clusters : The number of clusters to be generated by the SpectralNet algorithm. Also used for the dimention of the projection subspace.
        should_use_ae : bool, optional (default=False) Specifies whether to use the Autoencoder (AE) network as part of the training process.
        should_use_siamese : bool, optional (default=False) Specifies whether to use the Siamese network as part of the training process.
        is_sparse_graph : bool, optional (default=False) Specifies whether the graph Laplacian created from the data is sparse.
        ae_hiddens : list, optional (default=[512, 512, 2048, 10]) The number of hidden units in each layer of the Autoencoder network.
        ae_epochs : int, optional (default=30) The number of epochs to train the Autoencoder network.
        ae_lr : float, optional (default=1e-3) The learning rate for the Autoencoder network.
        ae_lr_decay : float, optional (default=0.1) The learning rate decay factor for the Autoencoder network.
        ae_min_lr : float, optional (default=1e-7) The minimum learning rate for the Autoencoder network.
        ae_patience : int, optional (default=10) The number of epochs to wait before reducing the learning rate for the Autoencoder network.
        ae_batch_size : int, optional (default=256) The batch size used during training of the Autoencoder network.
        siamese_hiddens : list, optional (default=[1024, 1024, 512, 10]) The number of hidden units in each layer of the Siamese network.
        siamese_epochs : int, optional (default=30) The number of epochs to train the Siamese network.
        siamese_lr : float, optional (default=1e-3) The learning rate for the Siamese network.
        siamese_lr_decay : float, optional (default=0.1) The learning rate decay factor for the Siamese network.    
        siamese_min_lr : float, optional (default=1e-7) The minimum learning rate for the Siamese network.  
        siamese_patience : int, optional (default=10) The number of epochs to wait before reducing the learning rate for the Siamese network.
        siamese_n_nbg : int, optional (default=2) The number of nearest neighbors to consider as 'positive' pairs by the Siamese network.
        siamese_use_approx : bool, optional (default=False) Specifies whether to use Annoy instead of KNN for computing nearest neighbors, particularly useful for large datasets.
        siamese_batch_size : int, optional (default=256) The batch size used during training of the Siamese network.
        spectral_hiddens : list, optional (default=[1024, 1024, 512, 10]) The number of hidden units in each layer of the Spectral network.
        spectral_epochs : int, optional (default=30) The number of epochs to train the Spectral network.
        spectral_lr : float, optional (default=1e-3) The learning rate for the Spectral network.
        spectral_lr_decay : float, optional (default=0.1) The learning rate decay factor for the Spectral network.
        spectral_min_lr : float, optional (default=1e-8) The minimum learning rate for the Spectral network.
        spectral_patience : int, optional (default=10) The number of epochs to wait before reducing the learning rate for the Spectral network.
        spectral_n_nbg : int, optional (default=30) The number of nearest neighbors to consider as 'positive' pairs by the Spectral network.
        spectral_scale_k : int, optional (default=15) The number of nearest neighbors to consider as 'positive' pairs by the Spectral network.
        spectral_is_local_scale : bool, optional (default=True) Specifies whether the scale is local or global.
        spectral_batch_size : int, optional (default=1024) The batch size used during training of the Spectral network.
        """
        self.n_clusters = n_clusters
        self.should_use_ae = should_use_ae
        self.should_use_siamese = should_use_siamese
        self.is_sparse_graph = is_sparse_graph
        self.ae_hiddens = ae_hiddens
        self.ae_epochs = ae_epochs
        self.ae_lr = ae_lr
        self.ae_lr_decay = ae_lr_decay
        self.ae_min_lr = ae_min_lr
        self.ae_patience = ae_patience
        self.ae_batch_size = ae_batch_size
        self.siamese_hiddens = siamese_hiddens
        self.siamese_epochs = siamese_epochs
        self.siamese_lr = siamese_lr
        self.siamese_lr_decay = siamese_lr_decay
        self.siamese_min_lr = siamese_min_lr
        self.siamese_patience = siamese_patience
        self.siamese_n_nbg = siamese_n_nbg
        self.siamese_use_approx = siamese_use_approx
        self.siamese_batch_size = siamese_batch_size
        self.spectral_hiddens = spectral_hiddens
        self.spectral_epochs = spectral_epochs
        self.spectral_lr = spectral_lr
        self.spectral_lr_decay = spectral_lr_decay
        self.spectral_min_lr = spectral_min_lr
        self.spectral_patience = spectral_patience
        self.spectral_n_nbg = spectral_n_nbg
        self.spectral_scale_k = spectral_scale_k
        self.spectral_is_local_scale = spectral_is_local_scale
        self.spectral_batch_size = spectral_batch_size
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        self._validate_spectral_hiddens()

    def _validate_spectral_hiddens(self):
        # Validates the number of hidden units in each layer of the Spectral network.

        if self.spectral_hiddens[-1] != self.n_clusters:
            raise ValueError("The number of units in the last layer of spectral_hiddens network must be equal to the number of clusters or components.")

    def fit(self, X: torch.Tensor, y: torch.Tensor = None):
        # Performs the main training loop for the SpectralNet model. X: Data to train the networks on. y: Labels in case there are any. Defaults to None.
        self._X = X
        ae_config = {"hiddens": self.ae_hiddens, "epochs": self.ae_epochs, "lr": self.ae_lr, "lr_decay": self.ae_lr_decay, "min_lr": self.ae_min_lr, "patience": self.ae_patience, "batch_size": self.ae_batch_size}
        siamese_config = {"hiddens": self.siamese_hiddens, "epochs": self.siamese_epochs, "lr": self.siamese_lr, "lr_decay": self.siamese_lr_decay, "min_lr": self.siamese_min_lr, "patience": self.siamese_patience, "n_nbg": self.siamese_n_nbg, "use_approx": self.siamese_use_approx, "batch_size": self.siamese_batch_size}
        spectral_config = {"hiddens": self.spectral_hiddens, "epochs": self.spectral_epochs, "lr": self.spectral_lr, "lr_decay": self.spectral_lr_decay, "min_lr": self.spectral_min_lr, "patience": self.spectral_patience, "n_nbg": self.spectral_n_nbg, "scale_k": self.spectral_scale_k, "is_local_scale": self.spectral_is_local_scale, "batch_size": self.spectral_batch_size}
        if self.should_use_ae:
            self.ae_trainer = AETrainer(config=ae_config, device=self.device)
            self.ae_net = self.ae_trainer.train(X)
            X = self.ae_trainer.embed(X)
        if self.should_use_siamese:
            self.siamese_trainer = SiameseTrainer(config=siamese_config, device=self.device)
            self.siamese_net = self.siamese_trainer.train(X)
        else:
            self.siamese_net = None
        is_sparse = self.is_sparse_graph
        if is_sparse:
            build_ann(X)
        self.spectral_trainer = SpectralTrainer(config=spectral_config, device=self.device, is_sparse=is_sparse)
        self.spec_net = self.spectral_trainer.train(X, y, self.siamese_net)

    def predict(self, X: torch.Tensor) -> np.ndarray:
        # Predicts the cluster assignments for the given data.
        X = X.view(X.size(0), -1)
        X = X.to(self.device)
        with torch.no_grad():
            if self.should_use_ae:
                X = self.ae_net.encode(X)
            self.embeddings_ = self.spec_net(X, should_update_orth_weights=False)
            self.embeddings_ = self.embeddings_.detach().cpu().numpy()
        cluster_assignments = self._get_clusters_by_kmeans(self.embeddings_)
        return cluster_assignments

    def get_random_batch(self, batch_size: int = 1024) -> tuple:
        # Get a batch of the input data.
        permuted_indices = torch.randperm(batch_size)
        X_raw = self._X.view(self._X.size(0), -1)
        X_encoded = X_raw
        if self.should_use_ae:
            X_encoded = self.ae_trainer.embed(self._X)
        if self.should_use_siamese:
            X_encoded = self.siamese_net.forward_once(X_encoded)
        X_encoded = X_encoded[permuted_indices]
        X_raw = X_raw[permuted_indices]
        X_encoded = X_encoded.to(self.device)
        return X_raw, X_encoded

    def _get_clusters_by_kmeans(self, embeddings: np.ndarray) -> np.ndarray:
        # Performs k-means clustering on the spectral-embedding space.
        kmeans = KMeans(n_clusters=self.n_clusters, n_init=10).fit(embeddings)
        cluster_assignments = kmeans.predict(embeddings)
        return cluster_assignments


class SpectralReduction:
    def __init__(
        self,
        n_components: int,
        should_use_ae: bool = False,
        should_use_siamese: bool = False,
        is_sparse_graph: bool = False,
        ae_hiddens: list = [512, 512, 2048, 10],
        ae_epochs: int = 40,
        ae_lr: float = 1e-3,
        ae_lr_decay: float = 0.1,
        ae_min_lr: float = 1e-7,
        ae_patience: int = 10,
        ae_batch_size: int = 256,
        siamese_hiddens: list = [1024, 1024, 512, 10],
        siamese_epochs: int = 30,
        siamese_lr: float = 1e-3,
        siamese_lr_decay: float = 0.1,
        siamese_min_lr: float = 1e-7,
        siamese_patience: int = 10,
        siamese_n_nbg: int = 2,
        siamese_use_approx: bool = False,
        siamese_batch_size: int = 128,
        spectral_hiddens: list = [1024, 1024, 512, 10],
        spectral_epochs: int = 30,
        spectral_lr: float = 1e-3,
        spectral_lr_decay: float = 0.1,
        spectral_min_lr: float = 1e-8,
        spectral_patience: int = 10,
        spectral_batch_size: int = 1024,
        spectral_n_nbg: int = 30,
        spectral_scale_k: int = 15,
        spectral_is_local_scale: bool = True,
    ):
        """ SpectralReduction is a class for implementing a Deep learning model that performs spectral clustering.
        This model optionally utilizes Autoencoders (AE) and Siamese networks for training.
        Parameters
        ----------
        n_components : int The number of components to keep.
        should_use_ae : bool, optional (default=False) Specifies whether to use the Autoencoder (AE) network as part of the training process.
        should_use_siamese : bool, optional (default=False) Specifies whether to use the Siamese network as part of the training process.
        is_sparse_graph : bool, optional (default=False) Specifies whether the graph Laplacian created from the data is sparse.
        ae_hiddens : list, optional (default=[512, 512, 2048, 10]) The number of hidden units in each layer of the Autoencoder network.
        ae_epochs : int, optional (default=30) The number of epochs to train the Autoencoder network.
        ae_lr : float, optional (default=1e-3) The learning rate for the Autoencoder network.
        ae_lr_decay : float, optional (default=0.1) The learning rate decay factor for the Autoencoder network.
        ae_min_lr : float, optional (default=1e-7) The minimum learning rate for the Autoencoder network.
        ae_patience : int, optional (default=10) The number of epochs to wait before reducing the learning rate for the Autoencoder network.
        ae_batch_size : int, optional (default=256) The batch size used during training of the Autoencoder network.
        siamese_hiddens : list, optional (default=[1024, 1024, 512, 10]) The number of hidden units in each layer of the Siamese network.
        siamese_epochs : int, optional (default=30) The number of epochs to train the Siamese network.
        siamese_lr : float, optional (default=1e-3) The learning rate for the Siamese network.
        siamese_lr_decay : float, optional (default=0.1) The learning rate decay factor for the Siamese network.
        siamese_min_lr : float, optional (default=1e-7) The minimum learning rate for the Siamese network.
        siamese_patience : int, optional (default=10) The number of epochs to wait before reducing the learning rate for the Siamese network.
        siamese_n_nbg : int, optional (default=2) The number of nearest neighbors to consider as 'positive' pairs by the Siamese network.
        siamese_use_approx : bool, optional (default=False) Specifies whether to use Annoy instead of KNN for computing nearest neighbors, particularly useful for large datasets.
        siamese_batch_size : int, optional (default=256) The batch size used during training of the Siamese network.
        spectral_hiddens : list, optional (default=[1024, 1024, 512, 10]) The number of hidden units in each layer of the Spectral network.
        spectral_epochs : int, optional (default=30) The number of epochs to train the Spectral network.
        spectral_lr : float, optional (default=1e-3) The learning rate for the Spectral network.
        spectral_lr_decay : float, optional (default=0.1) The learning rate decay factor for the Spectral network.
        spectral_min_lr : float, optional (default=1e-8) The minimum learning rate for the Spectral network.
        spectral_patience : int, optional (default=10) The number of epochs to wait before reducing the learning rate for the Spectral network.
        spectral_n_nbg : int, optional (default=30) The number of nearest neighbors to consider as 'positive' pairs by the Spectral network.
        spectral_scale_k : int, optional (default=15) The number of nearest neighbors to consider as 'positive' pairs by the Spectral network.
        spectral_is_local_scale : bool, optional (default=True) Specifies whether the scale is local or global.
        spectral_batch_size : int, optional (default=1024) The batch size used during training of the Spectral network.
        """
        self.n_components = n_components
        self.should_use_ae = should_use_ae
        self.should_use_siamese = should_use_siamese
        self.is_sparse_graph = is_sparse_graph
        self.ae_hiddens = ae_hiddens
        self.ae_epochs = ae_epochs
        self.ae_lr = ae_lr
        self.ae_lr_decay = ae_lr_decay
        self.ae_min_lr = ae_min_lr
        self.ae_patience = ae_patience
        self.ae_batch_size = ae_batch_size
        self.siamese_hiddens = siamese_hiddens
        self.siamese_epochs = siamese_epochs
        self.siamese_lr = siamese_lr
        self.siamese_lr_decay = siamese_lr_decay
        self.siamese_min_lr = siamese_min_lr
        self.siamese_patience = siamese_patience
        self.siamese_n_nbg = siamese_n_nbg
        self.siamese_use_approx = siamese_use_approx
        self.siamese_batch_size = siamese_batch_size
        self.spectral_hiddens = spectral_hiddens
        self.spectral_epochs = spectral_epochs
        self.spectral_lr = spectral_lr
        self.spectral_lr_decay = spectral_lr_decay
        self.spectral_min_lr = spectral_min_lr
        self.spectral_patience = spectral_patience
        self.spectral_n_nbg = spectral_n_nbg
        self.spectral_scale_k = spectral_scale_k
        self.spectral_is_local_scale = spectral_is_local_scale
        self.spectral_batch_size = spectral_batch_size
        self.X_new = None

    def _fit(self, X: torch.Tensor, y: torch.Tensor) -> np.ndarray:
        # Fit the SpectralNet model to the input data.
        self._spectralnet = SpectralNet(
            n_clusters=self.n_components,
            should_use_ae=self.should_use_ae,
            should_use_siamese=self.should_use_siamese,
            is_sparse_graph=self.is_sparse_graph,
            ae_hiddens=self.ae_hiddens,
            ae_epochs=self.ae_epochs,
            ae_lr=self.ae_lr,
            ae_lr_decay=self.ae_lr_decay,
            ae_min_lr=self.ae_min_lr,
            ae_patience=self.ae_patience,
            ae_batch_size=self.ae_batch_size,
            siamese_hiddens=self.siamese_hiddens,
            siamese_epochs=self.siamese_epochs,
            siamese_lr=self.siamese_lr,
            siamese_lr_decay=self.siamese_lr_decay,
            siamese_min_lr=self.siamese_min_lr,
            siamese_patience=self.siamese_patience,
            siamese_n_nbg=self.siamese_n_nbg,
            siamese_use_approx=self.siamese_use_approx,
            siamese_batch_size=self.siamese_batch_size,
            spectral_hiddens=self.spectral_hiddens,
            spectral_epochs=self.spectral_epochs,
            spectral_lr=self.spectral_lr,
            spectral_lr_decay=self.spectral_lr_decay,
            spectral_min_lr=self.spectral_min_lr,
            spectral_patience=self.spectral_patience,
            spectral_n_nbg=self.spectral_n_nbg,
            spectral_scale_k=self.spectral_scale_k,
            spectral_is_local_scale=self.spectral_is_local_scale,
            spectral_batch_size=self.spectral_batch_size,
        )
        self._spectralnet.fit(X, y)

    def _predict(self, X: torch.Tensor) -> np.ndarray:
        # Predict embeddings for the input data using the fitted SpectralNet model.
        self._spectralnet.predict(X)
        return self._spectralnet.embeddings_

    def _transform(self, X: torch.Tensor) -> np.ndarray:
        # Transform the input data into embeddings using the fitted SpectralNet model
        return self._predict(X)

    def fit_transform(self, X: torch.Tensor, y: torch.Tensor = None) -> np.ndarray:
        # Fit the SpectralNet model to the input data and transform it into embeddings.
        self._fit(X, y)
        return self._transform(X)

    def _get_laplacian_of_small_batch(self, batch: torch.Tensor) -> np.ndarray:
        # Get the Laplacian of a small batch of the input data
        W = get_affinity_matrix(batch, self.spectral_n_nbg, self._spectralnet.device)
        L = get_laplacian(W)
        return L

    def _remove_smallest_eigenvector(self, V: np.ndarray) -> np.ndarray:
        # Remove the constant eigenvector from the eigenvectors of the Laplacian of a small batch of the input data.
        batch_raw, batch_encoded = self._spectralnet.get_random_batch()
        L_batch = self._get_laplacian_of_small_batch(batch_encoded)
        V_batch = self._predict(batch_raw)
        eigenvalues = np.diag(V_batch.T @ L_batch @ V_batch)
        indices = np.argsort(eigenvalues)
        smallest_index = indices[0]
        V = V[:, np.arange(V.shape[1]) != smallest_index]
        V = V[:,(np.arange(V.shape[1]) == indices[1]) | (np.arange(V.shape[1]) == indices[2])]
        return V

    def visualize(self, V: np.ndarray, y: torch.Tensor = None, n_components: int = 1) -> None:
        # Visualize the embeddings of the input data using the fitted SpectralNet model.
        V = self._remove_smallest_eigenvector(V)
        print(V.shape)
        plot_laplacian_eigenvectors(V, y)
        cluster_labels = self._get_clusters_by_kmeans(V)
        acc = Metrics.acc_score(cluster_labels, y.detach().cpu().numpy(), n_clusters=10)
        print("acc with 2 components: ", acc)
        if n_components > 1:
            x_axis = V[:, 0]
            y_axis = V[:, 1]
        elif n_components == 1:
            x_axis = V
            y_axis = np.zeros_like(V)
        else:
            raise ValueError("n_components must be a positive integer (greater than 0)")
        if y is None:
            plt.scatter(x_axis, y_axis)
        else:
            plt.scatter(x_axis, y_axis, c=y, cmap="tab10", s=3)
        plt.show()

    def _get_clusters_by_kmeans(self, embeddings: np.ndarray) -> np.ndarray:
        # Performs k-means clustering on the spectral-embedding space.
        kmeans = KMeans(n_clusters=self.n_components, n_init=10).fit(embeddings)
        cluster_assignments = kmeans.predict(embeddings)
        return cluster_assignments
    
def cluster_twomoons():
    x_train, x_test, y_train, y_test = load_data("twomoons")
    X = torch.cat([x_train, x_test])
    y = torch.cat([y_train, y_test])
    spectralnet = SpectralNet(n_clusters=2, should_use_ae=False, should_use_siamese=False, spectral_batch_size=712, spectral_epochs=40, spectral_is_local_scale=False, spectral_n_nbg=8, spectral_scale_k=2, spectral_lr=1e-2, spectral_hiddens=[128, 128, 2])
    spectralnet.fit(X, y)
    cluster_assignments = spectralnet.predict(X)
    embeddings = spectralnet.embeddings_
    y = y.detach().cpu().numpy()
    acc_score = Metrics.acc_score(cluster_assignments, y, n_clusters=2)
    nmi_score = Metrics.nmi_score(cluster_assignments, y)
    print(f"ACC: {np.round(acc_score, 3)}")
    print(f"NMI: {np.round(nmi_score, 3)}")

def cluster_mnist():
    x_train, x_test, y_train, y_test = load_data("mnist")
    X = torch.cat([x_train, x_test])
    y = torch.cat([y_train, y_test])
    spectralnet = SpectralNet(n_clusters=10, should_use_ae=True, should_use_siamese=True)
    spectralnet.fit(X, y)
    cluster_assignments = spectralnet.predict(X)
    embeddings = spectralnet.embeddings_
    y = y.detach().cpu().numpy()
    acc_score = Metrics.acc_score(cluster_assignments, y, n_clusters=10)
    nmi_score = Metrics.nmi_score(cluster_assignments, y)
    print(f"ACC: {np.round(acc_score, 3)}")
    print(f"NMI: {np.round(nmi_score, 3)}")

def main_mnist_reduction():
    x_train, x_test, y_train, y_test = load_data("mnist")
    X = torch.cat([x_train, x_test])
    y = torch.cat([y_train, y_test])
    spectralreduction = SpectralReduction(n_components=3, should_use_ae=True, should_use_siamese=True, spectral_hiddens=[512, 512, 2048, 3])
    X_new = spectralreduction.fit_transform(X)
    spectralreduction.visualize(X_new, y, n_components=2)

def main_twomoons_reduction():
    x_train, x_test, y_train, y_test = load_data("twomoons")
    X = torch.cat([x_train, x_test])
    y = torch.cat([y_train, y_test])
    spectralreduction = SpectralReduction(n_components=2, should_use_ae=False, should_use_siamese=False, spectral_batch_size=712, spectral_epochs=40, spectral_is_local_scale=False, spectral_n_nbg=8, spectral_scale_k=2, spectral_lr=1e-2, spectral_hiddens=[128, 128, 2])
    X_new = spectralreduction.fit_transform(X)
    spectralreduction.visualize(X_new, y, n_components=1)

if __name__ == "__main__":
    cluster_twomoons()
    cluster_mnist()
    main_mnist_reduction()
    main_twomoons_reduction()
    